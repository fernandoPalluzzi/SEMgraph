% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/semLearn.R
\name{model.learn}
\alias{model.learn}
\title{Data-driven model learning}
\usage{
model.learn(
  graph,
  data,
  group = NULL,
  method = "TO",
  beta = 0,
  dag.only = FALSE,
  cluster = "wtc",
  hidden = "LV",
  min.clust = 5,
  edge.weights = TRUE
)
}
\arguments{
\item{graph}{Input network as an igraph object.}

\item{data}{A matrix or data.frame. Rows correspond to subjects, and
columns to graph nodes (variables).}

\item{group}{A binary vector. This vector must be as long as the number of 
subjects. Each vector element must be 1 for cases and 0 for control subjects. 
If NULL (default), group influence will not be considered.}

\item{method}{Linear order method. If \code{method = "TO"}, the topological order 
of the input DAG is enabled (default). If code{method = "TD"} a data-driven 
top-down minimum conditional variance method is performed.}

\item{beta}{Numeric value corresponding to the minimum LASSO beta coefficient 
needed for a new interaction to be retained in the final model (default = 0).
Increasing \code{beta} values decrease output model density and generally 
increase the number of output clusters.}

\item{dag.only}{A logical value. If FALSE (default), inferred connections 
will be added to the input graph. If TRUE, only inferred connections will 
be retained in the output. In this case, the output network will be a 
directed acyclic graph. See \code{\link[SEMgraph]{SEMdag}} for details.}

\item{cluster}{Graph clustering method. Basic clustering methods are taken 
from the igraph package, including: "wtc" (default value; walktrap community 
structure with short random walks), "ebc" (edge betweenness clustering), 
"fgc" (fast greedy method), "lbc" (label propagation method), "lec" (leading 
eigenvector method), "loc" (multi-level optimization), "opc" (optimal 
communiy structure), "sgc" (spinglass statistical mechanics). 
If type = "tahc", network modules are generated using the tree agglomerative 
hierarchical clustering method (Yu et al., 2015).
Clustering can be disabled by setting \code{cluster = NULL}.}

\item{hidden}{Hidden model type. For each defined hidden module: 
(i) if HM = "LV", a latent variable (LV) will be defined as common unknown 
cause acting on cluster nodes; (ii) if HM = "CV", cluster nodes will be 
considered as regressors of a latent composite variable (CV); 
(iii) if HM = "UV", an unmeasured variable (UV) model will be generated for 
each module, where source nodes (i.e., in-degree = 0) act as common 
regressors influencing the other nodes via an unmeasured variable. 
By default, HM is set to "LV" (i.e., the latent variable model).}

\item{min.clust}{Minimum size for a cluster to be fitted (default = 5). 
Ignored if \code{cluster = NULL}.}

\item{edge.weights}{Logical value. If TRUE, the resulting network is 
weighted using the r2z method (see \code{\link[SEMgraph]{weightGraph}}).}

\item{...}{Currently ignored.}
}
\value{
A list of two objects:
\enumerate{
\item "model", The output model as an igraph object;
\item "clusters", A list containing model clustering results.
It includes tree more objects:
\itemize{
\item "membership", A vector reporting cluster membership for each node;
\item "fit", hidden model fitting as a lavaan object;
\item "dataHM", data matrix containing cluster scores (hidden variables) 
alongside the original data variables.
}
}
}
\description{
Data-driven model structure learning based on the linear 
order provided by the input graph.
}
\examples{

library(huge)
als.npn <- huge.npn(alsData$exprs)

# Model learning
model <- model.learn(graph = alsData$graph, data = als.npn,
                     group = alsData$group, method = "TO",
                     beta = 0)

}
\references{
Grassi M, Palluzzi F, Tarantino B (2022). SEMgraph: An R Package for Causal Network
Analysis of High-Throughput Data with Structural Equation Models.
Bioinformatics, 38 (20), 4829–4830 <https://doi.org/10.1093/bioinformatics/btac567>

Tibshirani R, Bien J, Friedman J, Hastie T, Simon N, Taylor J,
Tibshirani RJ (2012). Strong rules for discarding predictors in
lasso type problems. Royal Statistical Society: Series B
(Statistical Methodology), 74(2): 245-266.
<https://doi.org/10.1111/j.1467-9868.2011.01004.x>

Shojaie A, Michailidis G (2010). Penalized likelihood methods for
estimation of sparse high-dimensional directed acyclic graphs.
Biometrika, 97(3): 519-538. <https://doi.org/10.1093/biomet/asq038>

Jankova J, van de Geer S (2015). Confidence intervals for high-dimensional
inverse covariance estimation. Electronic Journal of Statistics,
9(1): 1205-1229. <https://doi.org/10.1214/15-EJS1031>

Peters J, Bühlmann P (2014). Identifiability of Gaussian structural equation
models with equal error variances. Biometrika, 101(1):219–228.

Chen W, Drton M, Wang YS (2019). On Causal Discovery with an Equal-Variance
Assumption. Biometrika, 106(4): 973-980.
}
\seealso{
\code{\link[SEMgraph]{SEMdag}} for data-driven DAG learning details.
}
\author{
Fernando Palluzzi \email{fernando.palluzzi@gmail.com}
}
